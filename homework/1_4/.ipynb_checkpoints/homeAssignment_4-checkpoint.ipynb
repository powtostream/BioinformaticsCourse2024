{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Домашнее задание №4\n",
    "\n",
    "## Задача №0 (3)\n",
    "Дорешайте задачу про риды и BWT из файла practice4.ipynb. В ответе помимо кода укажите количество ридов первой, второй и третьей категории, а также вкратце опишите ход решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "Это домашнее задание можно выполнять целиком в этом ноутбуке, либо алгоритмы написать в отдельном файле и импортировать сюда, для использования. В папке data лежат два файла islands.fasta и nonIslands.fasta. В них хранятся прочтения из CpG островков и из обычных участков генома соответственно, этими данными нужно будет воспользоваться в первом задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №1 (1)\n",
    "Определите частоты генерации для каждого из нуклеотидов внутри CpG островков и вне их. Посчитайте так-же частоты для всех упорядоченных пар нуклеотидов и сравните частоту пары CG внутри островков и снаружи. Сделайте вывод. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_path = \"data/islands.fasta\"\n",
    "nonis_path = \"data/nonIslands.fasta\"\n",
    "islands = []\n",
    "islands_fasta = SeqIO.parse(is_path, \"fasta\")\n",
    "for record in islands_fasta.records:\n",
    "    islands.append(str(record.seq))\n",
    "\n",
    "nonislands_fasta = SeqIO.parse(nonis_path, \"fasta\")\n",
    "non_islands = []\n",
    "for record in nonislands_fasta.records:\n",
    "    non_islands.append(str(record.seq))\n",
    "\n",
    "nucleotides = [\"A\", \"C\", \"G\", \"T\"]\n",
    "islands_one = {k: 0 for k in nucleotides}\n",
    "non_islands_one = {k: 0 for k in nucleotides}\n",
    "\n",
    "pairs = [a+b for a in nucleotides for b in nucleotides]\n",
    "islands_pairs = {k: 0 for k in pairs}\n",
    "non_islands_pairs = {k: 0 for k in pairs}\n",
    "\n",
    "\n",
    "for seq in islands:\n",
    "    for i in range(len(seq)-1):\n",
    "        islands_pairs[seq[i]+seq[i+1]] += 1\n",
    "        islands_one[seq[i]] += 1\n",
    "    islands_one[seq[-1]] += 1\n",
    "\n",
    "\n",
    "for seq in non_islands:\n",
    "    for i in range(len(seq)-1):\n",
    "        non_islands_pairs[seq[i]+seq[i+1]] += 1\n",
    "        non_islands_one[seq[i]] += 1\n",
    "    non_islands_one[seq[-1]] += 1\n",
    "\n",
    "total_islands_ones = sum(islands_one.values())\n",
    "total_islands_pairs = total_islands_ones - len(islands)\n",
    "total_non_islands_ones = sum(non_islands_one.values())\n",
    "total_non_islands_pairs = total_non_islands_ones - len(non_islands)\n",
    "\n",
    "\n",
    "for n in nucleotides:\n",
    "    islands_one[n] /= total_islands_ones\n",
    "    non_islands_one[n] /= total_non_islands_ones\n",
    "\n",
    "for p in pairs:\n",
    "    islands_pairs[p] /= total_islands_pairs\n",
    "    non_islands_pairs[p] /= total_non_islands_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_islands_pairs: 1.0000000000000002\n",
      "non_islands_one: 1.0\n",
      "islands_pairs: 1.0\n",
      "islands_one: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"non_islands_pairs:\", sum(non_islands_pairs.values()))\n",
    "print(\"non_islands_one:\", sum(non_islands_one.values()))\n",
    "print(\"islands_pairs:\", sum(islands_pairs.values()))\n",
    "print(\"islands_one:\", sum(islands_one.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "islands: \n",
      " CG: 0.058983813569804595 C: 0.29639660831509845 G: 0.29827680525164113\n",
      "non_islands: \n",
      " CG: 0.0052779765716222836 C: 0.19613640750872205 G: 0.1984481597792771\n"
     ]
    }
   ],
   "source": [
    "print(\"islands: \\n\", \"CG:\", islands_pairs[\"CG\"], \"C:\", islands_one[\"C\"], \"G:\", islands_one[\"G\"])\n",
    "print(\"non_islands: \\n\", \"CG:\", non_islands_pairs[\"CG\"], \"C:\", non_islands_one[\"C\"], \"G:\", non_islands_one[\"G\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: в остравках цитозин и гуанин гораздо чаще встречается, чем вне их. Аналогично для пары CG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №2 (2)\n",
    "Напишите марковскую модель, которая имеет открытые состояния {A, T, G, C}, и скрытые состояния {+, -}. Когда модель в состоянии **+**, то вероятность генерации некоторого символа нуклеотида соответствует его частоте внутри CpG островков, вычислиному в первом задании, если состояние **-**, то частоте вне островков. Вероятность остаться внутри островка 0.95, а перейти в обычный геном 0.05. Для остальной части генома соответствующие вероятности 0.995 и 0.005. Саму модель можно реализовать в виде итератора, определив метод next, который возвращает пару - состояние и нуклеотид, который в этом состоянии произведен.    \n",
    "Воспользуйтесь данной моделью для того чтобы сгенерировать набор из 20 последовательностей длинной от 1 000 до 100 000, причем к каждой последовательности должна прилагаться последовательность состояний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'G', 'T']\n",
      "{'-': [0.28929861153616176, 0.19613640750872205, 0.1984481597792771, 0.3161168211758391], '+': [0.20246225382932168, 0.29639660831509845, 0.29827680525164113, 0.20286433260393874]}\n"
     ]
    }
   ],
   "source": [
    "# random.seed(3334)\n",
    "class Nucleotides_generator:\n",
    "    cur_state = \"-\"\n",
    "    # states = [\"-\", \"+\"]\n",
    "    stay_probs = {\"-\": ((\"-\", \"+\"), (0.995, 0.005)), \"+\": ((\"+\", \"-\"), (0.95, 0.05))}\n",
    "    nucl_probs = {\"-\": list(non_islands_one.values()), \"+\": list(islands_one.values())}\n",
    "    nucleotides = list(non_islands_one.keys())\n",
    "    print(nucleotides)\n",
    "    print(nucl_probs)\n",
    "\n",
    "    def __next__(self):\n",
    "        cur_data = self.stay_probs.get(self.cur_state)\n",
    "        self.cur_state = random.choices(cur_data[0], weights=cur_data[1], k=1)[0]\n",
    "        \n",
    "        nucleotid = random.choices(self.nucleotides, weights=self.nucl_probs.get(self.cur_state), k=1)[0]\n",
    "        return self.cur_state, nucleotid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list()\n",
    "states = list()\n",
    "\n",
    "for length in range(1000, 100001, 5000):\n",
    "# if True:\n",
    "    # length = 999999\n",
    "    new_seq = list()\n",
    "    new_states = list()\n",
    "    generator = Nucleotides_generator()\n",
    "    for i in range(length):\n",
    "        state, nucl = next(generator)\n",
    "        new_states.append(state)\n",
    "        new_seq.append(nucl)\n",
    "    seqs.append(new_seq)\n",
    "    states.append(new_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "A T T A T T T G A G T T A A G T A A C A T A T A G A C C G T G C G T T C A G A G T G G G A T A C C A G C T T G G T A G T\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "A C A A T A T A A A A T C C A A A T C T G T T T T C A G T T C A A G A C T G A A A T C A A T C T C A C A C G A T A G G G\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "T T A C A T C T T C T G T C T A T G A C A A A A A A A A A C T A T T C T G A A C A A T T G A A G C A G T C T G T C T G T\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + + + - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "T T A A C A G C T T T T G G G A G A A C T G T T T C T T T G C T C T T G A A C T C C G A T A A A A A A G A T T A G G A A\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "A A A C G T A A T A T A C C C G G A A T T A A A C A A G A T T A T A C A A T T A A A C G A A T T C T G T T A A T C C T T\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "G C C A T T C T C T A A T C A G T G C G A G T A A G G A T T T C T T T C A T A T T C A C T A A C A G G T G G A C T T T T\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "G G G A C G T T A T T G A A A A A G T T C T T A A T C T A A G C G T G T A A C A G T G A A G T T T A T A T A A G T T A C\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "T C A G T T A A A C A A T G T A T A T G G T C A C G C A C C A C A A T T C C T A T G A C C T G A T T G G T G G G G G C C\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + + + + + + + + +\n",
      "________________________________________________________________________________________________________________________\n",
      "C G G C T T T T C A G T A A T A G T A T C G G T C A T A G C A T A G G T C C G C T T A G T A T T T G C A T G A C A T A T\n",
      "+ + + + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "A G T T G T T T A T G C T A C G A C T G G C G A A T C A A A A G T T T A T C T T T T A T G G G T T A T G T T G T G T T C\n",
      "- - - - - - - - - - - - - + + + + + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "C T T T C T G G A C G C T G G A A T A C C T G C C G A T T T C T A T G A A G C C G C A C G T G T A C G T A G C T A T T G\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "G T T A A A G A T A T C A T G G A C T C T C A T A T T A A A G T G A A A C T A G A A G T T T T G T G A T C A T A A A G C\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "T T T A G A C T C T A A C A C C A T T A A T A T C C C T T G T A A C T T T T G A A A G G A A A C A A C C T A C C A T A A\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "T G C G T A C T G C C T A G T G T T C A T T C A C T A A A G T A T T T C A T T T C A T G T C C A C C A T A T G G T A C C\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "A A T C A G G C T C T T C T T C A T C C G G T T T A C T C G T A A T T C T T C A C T A G T A A T A A T G G A T G A A T C\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "G T A C C A G G G G G T T A A C A A T A G C C C T C T A G T A A C G A G A A G T G G T T G C A T C A C C T G C A C G A G\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "________________________________________________________________________________________________________________________\n",
      "T T G T T T T T G A T G G A A T C C A A C C T T T C A C T A C T C A A G A C T T\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - + + + + + + + + + + + + + + + +\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"_\"*120)\n",
    "for row in range(len(seqs[0])//60+1):\n",
    "    print(*seqs[0][row*60:(row+1)*60])\n",
    "    print(*states[0][row*60:(row+1)*60])\n",
    "    print(\"_\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №3 (4)\n",
    "Напишите алгоритм Витерби для восстановления последовательности скрытых состояний марковской модели из второго задаания. Воспользуйтесь им, воссстановив состояния тех последовательностей, которые вы получили во втором задании и посчитайте TP, TN, FP, FN по количеству правильно или ошибочно предсказанных позиций из CpG остравков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs to get to current state from + and -\n",
    "transfer_probs = {0: (0.995, 0.05), 1: (0.005, 0.95)}\n",
    "nucl_probs = {0: non_islands_one, 1: islands_one}\n",
    "\n",
    "def viterbi(seq):\n",
    "    s = 2  # number of states\n",
    "    st_dict = {0: \"-\", 1: \"+\"}\n",
    "    v = np.zeros(shape=(s, len(seq)+1))\n",
    "    prev = np.zeros(shape=(s, len(seq)+1)).astype(int)\n",
    "    # init_state = 0\n",
    "    # for i in range(s):\n",
    "        # v[i, 0] = np.log(transfer_probs[init_state][i])+np.log(nucl_probs[i][seq[0]])\n",
    "    v[0,-1] = 1\n",
    "    v[1,-1] = 0\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        for st in range(s):\n",
    "            # probs = [\n",
    "            #     np.log( nucl_probs[st][seq[i]]) +\n",
    "            #     np.log( transfer_probs[st][j]) +\n",
    "            #     v[j][i-1] for j in range(s)\n",
    "            # ]\n",
    "            # probs = np.array([\n",
    "            #     np.log(nucl_probs[st][seq[i]])+np.log(transfer_probs[st][j]) +\n",
    "            #     v[j][i-1] for j in range(s)\n",
    "            # ])\n",
    "            probs = np.array([\n",
    "                np.log(nucl_probs[st][seq[i]])+np.log(transfer_probs[st][j]) +\n",
    "                v[j][i-1] for j in range(s)\n",
    "            ])\n",
    "            max_ind = np.argmax(probs)\n",
    "            prev[st, i] = max_ind\n",
    "            v[st, i] = probs[max_ind]\n",
    "\n",
    "    result = [0] * len(seq)\n",
    "    final_state = np.argmax(v[:, -1])\n",
    "    \n",
    "    # final_state = random.choices([0, 1], weights = v[:, -1]/v[:, -1]), k=1)[0]\n",
    "    for i in range(len(seq)-1, -1, -1):\n",
    "        result[i] = st_dict.get(final_state)\n",
    "        final_state = prev[final_state, i+1]\n",
    "\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "def calc_metrics(true, pred):\n",
    "    metrics = {\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0}\n",
    "    for i, state in enumerate(true):\n",
    "        equal = state == pred[i]\n",
    "        if state == \"-\":\n",
    "            if equal:\n",
    "                metrics[\"TN\"] += 1\n",
    "            else:\n",
    "                metrics[\"FP\"] += 1\n",
    "        else:\n",
    "            if equal:\n",
    "                metrics[\"TP\"] += 1\n",
    "            else:\n",
    "                metrics[\"FN\"] += 1\n",
    "    # for key in metrics.keys():\n",
    "    #     metrics[key] /= len(true)\n",
    "    metrics[\"Recall\"] = f'{metrics[\"TP\"]/(metrics[\"TP\"]+ metrics[\"FN\"]):.3f}' if (metrics[\"TP\"]+ metrics[\"FN\"]) != 0 else 0\n",
    "    metrics[\"Precision\"] = f'{metrics[\"TP\"]/(metrics[\"TP\"]+metrics[\"FP\"]):.3f}' if (metrics[\"TP\"]+metrics[\"FP\"]) != 0 else 1\n",
    "    metrics[\"Accuracy\"] = f'{(metrics[\"TP\"]+metrics[\"TN\"])/len(true):.3f}'\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'TN': 962, 'FP': 0, 'FN': 38, 'Recall': '0.000', 'Precision': 1, 'Accuracy': '0.962'}\n",
      "{'TP': 236, 'TN': 5106, 'FP': 33, 'FN': 625, 'Recall': '0.274', 'Precision': '0.877', 'Accuracy': '0.890'}\n",
      "{'TP': 89, 'TN': 10067, 'FP': 8, 'FN': 836, 'Recall': '0.096', 'Precision': '0.918', 'Accuracy': '0.923'}\n",
      "{'TP': 33, 'TN': 15070, 'FP': 37, 'FN': 860, 'Recall': '0.037', 'Precision': '0.471', 'Accuracy': '0.944'}\n",
      "{'TP': 289, 'TN': 18732, 'FP': 40, 'FN': 1939, 'Recall': '0.130', 'Precision': '0.878', 'Accuracy': '0.906'}\n",
      "{'TP': 127, 'TN': 23327, 'FP': 7, 'FN': 2539, 'Recall': '0.048', 'Precision': '0.948', 'Accuracy': '0.902'}\n",
      "{'TP': 211, 'TN': 27892, 'FP': 39, 'FN': 2858, 'Recall': '0.069', 'Precision': '0.844', 'Accuracy': '0.907'}\n",
      "{'TP': 188, 'TN': 32603, 'FP': 22, 'FN': 3187, 'Recall': '0.056', 'Precision': '0.895', 'Accuracy': '0.911'}\n",
      "{'TP': 57, 'TN': 37406, 'FP': 31, 'FN': 3506, 'Recall': '0.016', 'Precision': '0.648', 'Accuracy': '0.914'}\n",
      "{'TP': 741, 'TN': 41228, 'FP': 154, 'FN': 3877, 'Recall': '0.160', 'Precision': '0.828', 'Accuracy': '0.912'}\n",
      "{'TP': 168, 'TN': 46831, 'FP': 0, 'FN': 4001, 'Recall': '0.040', 'Precision': '1.000', 'Accuracy': '0.922'}\n",
      "{'TP': 458, 'TN': 50426, 'FP': 10, 'FN': 5106, 'Recall': '0.082', 'Precision': '0.979', 'Accuracy': '0.909'}\n",
      "{'TP': 296, 'TN': 55605, 'FP': 54, 'FN': 5045, 'Recall': '0.055', 'Precision': '0.846', 'Accuracy': '0.916'}\n",
      "{'TP': 308, 'TN': 59812, 'FP': 16, 'FN': 5864, 'Recall': '0.050', 'Precision': '0.951', 'Accuracy': '0.911'}\n",
      "{'TP': 352, 'TN': 64504, 'FP': 143, 'FN': 6001, 'Recall': '0.055', 'Precision': '0.711', 'Accuracy': '0.913'}\n",
      "{'TP': 226, 'TN': 69088, 'FP': 57, 'FN': 6629, 'Recall': '0.033', 'Precision': '0.799', 'Accuracy': '0.912'}\n",
      "{'TP': 396, 'TN': 73554, 'FP': 3, 'FN': 7047, 'Recall': '0.053', 'Precision': '0.992', 'Accuracy': '0.913'}\n",
      "{'TP': 380, 'TN': 78371, 'FP': 67, 'FN': 7182, 'Recall': '0.050', 'Precision': '0.850', 'Accuracy': '0.916'}\n",
      "{'TP': 646, 'TN': 82218, 'FP': 263, 'FN': 7873, 'Recall': '0.076', 'Precision': '0.711', 'Accuracy': '0.911'}\n",
      "{'TP': 848, 'TN': 86446, 'FP': 226, 'FN': 8480, 'Recall': '0.091', 'Precision': '0.790', 'Accuracy': '0.909'}\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(seqs):\n",
    "    res = viterbi(seq)\n",
    "    metrics = calc_metrics(states[i], res)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №4 (4)\n",
    "Напишите алгоритм вперед назад для модели из второго задания. Пользуясь этим алгоритмом найдите вероятности того, что модель находилась в состоянии **+** для каждой позиции строк из второго задания. Устанавливая различные пороговые значения, определите позиции соответствующие CpG островкам и посчитайте TP. Постройте график зависимости TP от выбранного порогового значения. Есть ли пороговые значения при которых TP больше чем в задании №3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_probs = {0: (0.995, 0.005), 1: (0.05, 0.95)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_probs_as_logs(probs):\n",
    "    max_log = max(probs)\n",
    "    sum_exp_probs = np.exp(probs - max_log).sum()\n",
    "    return np.log(sum_exp_probs) + max_log\n",
    "\n",
    "def forward_backward(seq, threshold=0.15):\n",
    "    s = 2  # number of states\n",
    "    st_dict = {0: \"-\", 1: \"+\"}\n",
    "    v = np.zeros(shape=(s, len(seq)+1))\n",
    "    back = np.zeros(shape=(s, len(seq)+1))\n",
    "    probs = np.zeros(len(seq))\n",
    "    init_state = 0\n",
    "    # for i in range(s):\n",
    "    #     v[i, 0] = np.log(transfer_probs[init_state][i]) + np.log(\n",
    "    #         nucl_probs[i][seq[0]])\n",
    "        # v[i, 0] = transfer_probs[init_state][i])*nucl_probs[i][seq[0]]\n",
    "    v[0,0] = np.log(1)\n",
    "    v[1,0] = 0\n",
    "    for i in range(1, len(seq)+1):\n",
    "        for st in range(s):\n",
    "            # probs = np.array([\n",
    "            #     np.log(nucl_probs[st][seq[i]])+np.log(transfer_probs[st][j]) +\n",
    "            #     v[j][i-1] for j in range(s)\n",
    "            # ])\n",
    "            log_probs = np.array([\n",
    "                np.log(transfer_probs[st][j]) +\n",
    "                v[j][i - 1] for j in range(s)\n",
    "            ])\n",
    "            max_log = max(log_probs)\n",
    "            sum_exp_probs = np.exp(log_probs - max_log).sum()\n",
    "\n",
    "            # max_ind = np.argmax(probs)\n",
    "            # prev[st, i] = max_ind\n",
    "            v[st, i] = sum_probs_as_logs(log_probs) + np.log(\n",
    "                nucl_probs[st][seq[i-1]])\n",
    "\n",
    "    back[0, -1] = np.log(back_probs[0][0])\n",
    "    back[1, -1] = np.log(back_probs[1][1])\n",
    "    for i in range(len(seq)-2, -1, -1):\n",
    "        for st in range(s):\n",
    "            # probs = np.array([\n",
    "            #     np.log(nucl_probs[st][seq[i]])+np.log(transfer_probs[st][j]) +\n",
    "            #     v[j][i-1] for j in range(s)\n",
    "            # ])\n",
    "            log_probs = np.array([\n",
    "                np.log(back_probs[st][j]) + np.log(nucl_probs[j][seq[i+1]]) +\n",
    "                back[j][i + 1] for j in range(s)\n",
    "            ])\n",
    "            max_log = max(log_probs)\n",
    "            sum_exp_probs = np.exp(log_probs - max_log).sum()\n",
    "\n",
    "            # max_ind = np.argmax(probs)\n",
    "            # prev[st, i] = max_ind\n",
    "            back[st, i] = sum_probs_as_logs(log_probs)\n",
    "\n",
    "    final_P = back[0, 0]\n",
    "    print(final_P)\n",
    "    result = [0] * len(seq)\n",
    "    for i in range(0, len(seq)):\n",
    "        # print(v[1,i+1], back[1,i])\n",
    "        # probs[i] = np.exp(v[1,i+1]+back[1,i]-final_P)\n",
    "        probs[i] = np.exp(v[1,i+1]+back[1,i+1]-final_P)\n",
    "        # print(probs[i], i)\n",
    "    is_island = probs > threshold\n",
    "    for i in range(len(seq)):\n",
    "        if is_island[i]:\n",
    "            result[i] = \"+\"\n",
    "        else:\n",
    "            result[i] = \"-\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-15020.82862093069\n",
      "{'TP': 925, 'TN': 0, 'FP': 10075, 'FN': 0, 'Recall': '1.000', 'Precision': '0.084', 'Accuracy': '0.084'}\n",
      "0.05\n",
      "-15020.82862093069\n",
      "{'TP': 870, 'TN': 4185, 'FP': 5890, 'FN': 55, 'Recall': '0.941', 'Precision': '0.129', 'Accuracy': '0.460'}\n",
      "0.1\n",
      "-15020.82862093069\n",
      "{'TP': 780, 'TN': 6510, 'FP': 3565, 'FN': 145, 'Recall': '0.843', 'Precision': '0.180', 'Accuracy': '0.663'}\n",
      "0.15\n",
      "-15020.82862093069\n",
      "{'TP': 701, 'TN': 7639, 'FP': 2436, 'FN': 224, 'Recall': '0.758', 'Precision': '0.223', 'Accuracy': '0.758'}\n",
      "0.2\n",
      "-15020.82862093069\n",
      "{'TP': 646, 'TN': 8294, 'FP': 1781, 'FN': 279, 'Recall': '0.698', 'Precision': '0.266', 'Accuracy': '0.813'}\n",
      "0.25\n",
      "-15020.82862093069\n",
      "{'TP': 604, 'TN': 8649, 'FP': 1426, 'FN': 321, 'Recall': '0.653', 'Precision': '0.298', 'Accuracy': '0.841'}\n",
      "0.3\n",
      "-15020.82862093069\n",
      "{'TP': 571, 'TN': 8881, 'FP': 1194, 'FN': 354, 'Recall': '0.617', 'Precision': '0.324', 'Accuracy': '0.859'}\n",
      "0.35\n",
      "-15020.82862093069\n",
      "{'TP': 544, 'TN': 9059, 'FP': 1016, 'FN': 381, 'Recall': '0.588', 'Precision': '0.349', 'Accuracy': '0.873'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 36, 5):\n",
    "    threshold = i / 100\n",
    "    print(threshold)\n",
    "    res = forward_backward(seqs[2], threshold)\n",
    "    metrics = calc_metrics(states[2], res)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "-8247.582660082773\n",
      "{'TP': 777, 'TN': 4063, 'FP': 1076, 'FN': 84, 'Recall': '0.902', 'Precision': '0.419', 'Accuracy': '0.807'}\n",
      "0.16\n",
      "-8247.582660082773\n",
      "{'TP': 774, 'TN': 4137, 'FP': 1002, 'FN': 87, 'Recall': '0.899', 'Precision': '0.436', 'Accuracy': '0.819'}\n",
      "0.17\n",
      "-8247.582660082773\n",
      "{'TP': 768, 'TN': 4201, 'FP': 938, 'FN': 93, 'Recall': '0.892', 'Precision': '0.450', 'Accuracy': '0.828'}\n",
      "0.18\n",
      "-8247.582660082773\n",
      "{'TP': 761, 'TN': 4258, 'FP': 881, 'FN': 100, 'Recall': '0.884', 'Precision': '0.463', 'Accuracy': '0.837'}\n",
      "0.19\n",
      "-8247.582660082773\n",
      "{'TP': 754, 'TN': 4308, 'FP': 831, 'FN': 107, 'Recall': '0.876', 'Precision': '0.476', 'Accuracy': '0.844'}\n",
      "0.2\n",
      "-8247.582660082773\n",
      "{'TP': 750, 'TN': 4351, 'FP': 788, 'FN': 111, 'Recall': '0.871', 'Precision': '0.488', 'Accuracy': '0.850'}\n",
      "0.21\n",
      "-8247.582660082773\n",
      "{'TP': 743, 'TN': 4383, 'FP': 756, 'FN': 118, 'Recall': '0.863', 'Precision': '0.496', 'Accuracy': '0.854'}\n",
      "0.22\n",
      "-8247.582660082773\n",
      "{'TP': 738, 'TN': 4423, 'FP': 716, 'FN': 123, 'Recall': '0.857', 'Precision': '0.508', 'Accuracy': '0.860'}\n",
      "0.23\n",
      "-8247.582660082773\n",
      "{'TP': 731, 'TN': 4467, 'FP': 672, 'FN': 130, 'Recall': '0.849', 'Precision': '0.521', 'Accuracy': '0.866'}\n",
      "0.24\n",
      "-8247.582660082773\n",
      "{'TP': 727, 'TN': 4504, 'FP': 635, 'FN': 134, 'Recall': '0.844', 'Precision': '0.534', 'Accuracy': '0.872'}\n",
      "0.25\n",
      "-8247.582660082773\n",
      "{'TP': 724, 'TN': 4539, 'FP': 600, 'FN': 137, 'Recall': '0.841', 'Precision': '0.547', 'Accuracy': '0.877'}\n",
      "0.26\n",
      "-8247.582660082773\n",
      "{'TP': 719, 'TN': 4577, 'FP': 562, 'FN': 142, 'Recall': '0.835', 'Precision': '0.561', 'Accuracy': '0.883'}\n",
      "0.27\n",
      "-8247.582660082773\n",
      "{'TP': 717, 'TN': 4608, 'FP': 531, 'FN': 144, 'Recall': '0.833', 'Precision': '0.575', 'Accuracy': '0.887'}\n",
      "0.28\n",
      "-8247.582660082773\n",
      "{'TP': 712, 'TN': 4635, 'FP': 504, 'FN': 149, 'Recall': '0.827', 'Precision': '0.586', 'Accuracy': '0.891'}\n",
      "0.29\n",
      "-8247.582660082773\n",
      "{'TP': 706, 'TN': 4665, 'FP': 474, 'FN': 155, 'Recall': '0.820', 'Precision': '0.598', 'Accuracy': '0.895'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(15, 30, 1):\n",
    "    threshold = i / 100\n",
    "    print(threshold)\n",
    "    res = forward_backward(seqs[1], threshold)\n",
    "    metrics = calc_metrics(states[1], res)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1354.5694007766374\n",
      "{'TP': 13, 'TN': 954, 'FP': 8, 'FN': 25, 'Recall': '0.342', 'Precision': '0.619', 'Accuracy': '0.967'}\n",
      "-8247.582660082773\n",
      "{'TP': 712, 'TN': 4635, 'FP': 504, 'FN': 149, 'Recall': '0.827', 'Precision': '0.586', 'Accuracy': '0.891'}\n",
      "-15020.82862093069\n",
      "{'TP': 583, 'TN': 8800, 'FP': 1275, 'FN': 342, 'Recall': '0.630', 'Precision': '0.314', 'Accuracy': '0.853'}\n",
      "-21859.80569325854\n",
      "{'TP': 749, 'TN': 10434, 'FP': 4673, 'FN': 144, 'Recall': '0.839', 'Precision': '0.138', 'Accuracy': '0.699'}\n",
      "-28761.85223676783\n",
      "{'TP': 1498, 'TN': 17118, 'FP': 1654, 'FN': 730, 'Recall': '0.672', 'Precision': '0.475', 'Accuracy': '0.886'}\n",
      "-35617.25596718272\n",
      "{'TP': 1783, 'TN': 20713, 'FP': 2621, 'FN': 883, 'Recall': '0.669', 'Precision': '0.405', 'Accuracy': '0.865'}\n",
      "-42439.90700002498\n",
      "{'TP': 2618, 'TN': 18781, 'FP': 9150, 'FN': 451, 'Recall': '0.853', 'Precision': '0.222', 'Accuracy': '0.690'}\n",
      "-49316.602976872346\n",
      "{'TP': 1756, 'TN': 30832, 'FP': 1793, 'FN': 1619, 'Recall': '0.520', 'Precision': '0.495', 'Accuracy': '0.905'}\n",
      "-56148.069812610316\n",
      "{'TP': 2339, 'TN': 33551, 'FP': 3886, 'FN': 1224, 'Recall': '0.656', 'Precision': '0.376', 'Accuracy': '0.875'}\n",
      "-63017.56948890938\n",
      "{'TP': 3354, 'TN': 37040, 'FP': 4342, 'FN': 1264, 'Recall': '0.726', 'Precision': '0.436', 'Accuracy': '0.878'}\n",
      "-69802.29641770932\n",
      "{'TP': 2531, 'TN': 42459, 'FP': 4372, 'FN': 1638, 'Recall': '0.607', 'Precision': '0.367', 'Accuracy': '0.882'}\n",
      "-76687.3413547921\n",
      "{'TP': 3353, 'TN': 46431, 'FP': 4005, 'FN': 2211, 'Recall': '0.603', 'Precision': '0.456', 'Accuracy': '0.889'}\n",
      "-83481.48928270617\n",
      "{'TP': 3516, 'TN': 48859, 'FP': 6800, 'FN': 1825, 'Recall': '0.658', 'Precision': '0.341', 'Accuracy': '0.859'}\n",
      "-90429.37092642285\n",
      "{'TP': 3673, 'TN': 55154, 'FP': 4674, 'FN': 2499, 'Recall': '0.595', 'Precision': '0.440', 'Accuracy': '0.891'}\n",
      "-97262.20414951585\n",
      "{'TP': 3907, 'TN': 58098, 'FP': 6549, 'FN': 2446, 'Recall': '0.615', 'Precision': '0.374', 'Accuracy': '0.873'}\n",
      "-104182.10714223415\n",
      "{'TP': 5633, 'TN': 52403, 'FP': 16742, 'FN': 1222, 'Recall': '0.822', 'Precision': '0.252', 'Accuracy': '0.764'}\n",
      "-110900.64713950362\n",
      "{'TP': 5263, 'TN': 60714, 'FP': 12843, 'FN': 2180, 'Recall': '0.707', 'Precision': '0.291', 'Accuracy': '0.815'}\n",
      "-117778.06238167484\n",
      "{'TP': 4562, 'TN': 71754, 'FP': 6684, 'FN': 3000, 'Recall': '0.603', 'Precision': '0.406', 'Accuracy': '0.887'}\n",
      "-124537.62265477591\n",
      "{'TP': 6224, 'TN': 69822, 'FP': 12659, 'FN': 2295, 'Recall': '0.731', 'Precision': '0.330', 'Accuracy': '0.836'}\n",
      "-131400.13482102662\n",
      "{'TP': 6565, 'TN': 74399, 'FP': 12273, 'FN': 2763, 'Recall': '0.704', 'Precision': '0.348', 'Accuracy': '0.843'}\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.28\n",
    "for i, seq in enumerate(seqs):\n",
    "    res = forward_backward(seq, threshold)\n",
    "    metrics = calc_metrics(states[i], res)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
